# Ray Peat Legacy - Bioenergetic Knowledge Platform
# Environment Configuration
# Copy this file to .env and fill in your actual values

# =================================================================
# Core Environment Settings
# =================================================================
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# =================================================================
# API Keys (Required for AI features)
# =================================================================
# Get Gemini API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# Optional: OpenAI API key for alternative LLM support
# OPENAI_API_KEY=your_openai_api_key_here

# Optional: Pinecone for vector database (alternative to ChromaDB)
# PINECONE_API_KEY=your_pinecone_api_key_here

# =================================================================
# Database Configuration
# =================================================================
# Local SQLite (default)
DATABASE_URL=sqlite:///./data/peat_legacy.db

# Or PostgreSQL for production:
# DATABASE_URL=postgresql://user:password@localhost:5432/peat_legacy

# Redis for caching (optional)
REDIS_URL=redis://localhost:6379

# =================================================================
# Vector Database Settings
# =================================================================
# Options: chromadb, pinecone, qdrant
VECTOR_DB_TYPE=chromadb

# =================================================================
# Processing Configuration
# =================================================================
BATCH_SIZE=10
MAX_TOKENS_PER_CHUNK=1000
CHUNK_OVERLAP=200

# =================================================================
# API Server Settings
# =================================================================
API_HOST=localhost
API_PORT=8000
API_WORKERS=1

# =================================================================
# AI Model Configuration
# =================================================================
# Embedding model for text vectorization
EMBEDDING_MODEL=text-embedding-004
EMBEDDING_DIMENSIONS=768

# Default LLM for generation
DEFAULT_LLM_MODEL=gemini-2.5-flash-lite
MAX_CONTEXT_LENGTH=32000
TEMPERATURE=0.1

# =================================================================
# Rate Limiting
# =================================================================
API_RATE_LIMIT=60
GEMINI_RATE_LIMIT=15

# =================================================================
# Security
# =================================================================
SECRET_KEY=your-secret-key-here-change-in-production
